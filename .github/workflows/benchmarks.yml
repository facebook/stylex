name: benchmarks

on: [pull_request]

jobs:
  perf:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 50
    - uses: actions/setup-node@v4
      with:
        node-version: '22.x'
    - name: 'Setup temporary files'
      run: |
        echo "BASE_JSON=$(mktemp)" >> $GITHUB_ENV
        echo "PATCH_JSON=$(mktemp)" >> $GITHUB_ENV
    - name: 'Benchmark base'
      run: |
        git checkout -f ${{ github.event.pull_request.base.sha }}
        git clean -fdx
        npm install --loglevel error
        if npm run perf -w benchmarks -- -o ${{ env.BASE_JSON }}; then
          echo "Ran successfully on base branch"
        else
          echo "{}" > ${{ env.BASE_JSON }}  # Empty JSON as default
          echo "Benchmark script not found on base branch, using default values"
        fi
    - name: 'Benchmark patch'
      run: |
        git checkout -f ${{ github.event.pull_request.head.sha }}
        git clean -fdx
        npm install --loglevel error
        npm run perf -w benchmarks -- -o ${{ env.PATCH_JSON }}
        echo "Ran successfully on patch branch"
    - name: 'Collect results'
      id: collect
      run: |
        echo "table<<EOF" >> $GITHUB_OUTPUT
        npm run compare -w benchmarks -- ${{ env.BASE_JSON }} ${{ env.PATCH_JSON }} >> markdown
        cat markdown >> $GITHUB_OUTPUT
        echo "EOF" >> $GITHUB_OUTPUT
    - name: 'Post comment'
      uses: edumserrano/find-create-or-update-comment@v3
      with:
        issue-number: ${{ github.event.pull_request.number }}
        body-includes: '<!-- workflow-benchmarks-perf-data -->'
        comment-author: 'github-actions[bot]'
        body: |
          <!-- workflow-benchmarks-perf-data -->
          ### workflow: benchmarks/perf
          Comparison of performance test results, measured in operations per second. Larger is better.
          ${{ steps.collect.outputs.table }}
        edit-mode: replace

  size:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 50
    - uses: actions/setup-node@v4
      with:
        node-version: '22.x'
    - name: 'Setup temporary files'
      run: |
        echo "BASE_JSON=$(mktemp)" >> $GITHUB_ENV
        echo "PATCH_JSON=$(mktemp)" >> $GITHUB_ENV
    - name: 'Benchmark base'
      run: |
        git checkout -f ${{ github.event.pull_request.base.sha }}
        git clean -fdx
        npm install --loglevel error
        if npm run size -w benchmarks -- -o ${{ env.BASE_JSON }}; then
          echo "Ran successfully on base branch"
        else
          echo "{}" > ${{ env.BASE_JSON }}  # Empty JSON as default
          echo "Benchmark script not found on base branch, using default values"
        fi
    - name: 'Benchmark patch'
      run: |
        git checkout -f ${{ github.event.pull_request.head.sha }}
        git clean -fdx
        npm install --loglevel error
        npm run size -w benchmarks -- -o ${{ env.PATCH_JSON }}
        echo "Ran successfully on patch branch"
    - name: 'Collect results'
      id: collect
      run: |
        echo "table<<EOF" >> $GITHUB_OUTPUT
        npm run compare -w benchmarks -- ${{ env.BASE_JSON }} ${{ env.PATCH_JSON }} >> markdown
        cat markdown >> $GITHUB_OUTPUT
        echo "EOF" >> $GITHUB_OUTPUT
    - name: 'Post comment'
      uses: edumserrano/find-create-or-update-comment@v3
      with:
        issue-number: ${{ github.event.pull_request.number }}
        body-includes: '<!-- workflow-benchmarks-size-data -->'
        comment-author: 'github-actions[bot]'
        body: |
          <!-- workflow-benchmarks-size-data -->
          ### workflow: benchmarks/size
          Comparison of minified (terser) and compressed (brotli) size results, measured in bytes. Smaller is better.
          ${{ steps.collect.outputs.table }}
        edit-mode: replace
